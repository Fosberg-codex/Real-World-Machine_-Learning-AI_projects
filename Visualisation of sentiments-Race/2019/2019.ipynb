{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2019.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "OvNlWZKO6vea",
        "outputId": "5bbf8077-9802-489c-e6a3-d287974b9c50"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a0aeb709ec43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# reading text file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2019.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# converting to lowercase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2019.txt'"
          ]
        }
      ],
      "source": [
        "import string\n",
        "from collections import Counter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# reading text file\n",
        "text = open(\"2019.txt\", encoding=\"utf-8\").read()\n",
        "\n",
        "# converting to lowercase\n",
        "lower_case = text.lower()\n",
        "\n",
        "# Removing punctuations\n",
        "cleaned_text = lower_case.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "# splitting text into words\n",
        "tokenized_words = cleaned_text.split()\n",
        "\n",
        "stop_words = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\",\n",
        "              \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\",\n",
        "              \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\",\n",
        "              \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\",\n",
        "              \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\",\n",
        "              \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\",\n",
        "              \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\",\n",
        "              \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\",\n",
        "              \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\n",
        "              \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
        "\n",
        "# Removing stop words from the tokenized words list\n",
        "final_words = []\n",
        "for word in tokenized_words:\n",
        "    if word not in stop_words:\n",
        "        final_words.append(word)\n",
        "\n",
        "# NLP Emotion Algorithm\n",
        "# 1) Check if the word in the final word list is also present in emotion.txt\n",
        "#  - open the emotion file\n",
        "#  - Loop through each line and clear it\n",
        "#  - Extract the word and emotion using split\n",
        "\n",
        "# 2) If word is present -> Add the emotion to emotion_list\n",
        "# 3) Finally count each emotion in the emotion list\n",
        "emotion_list = []\n",
        "with open('emotions.txt', 'r') as file:\n",
        "    for line in file:\n",
        "        clear_line = line.replace(\"\\n\", '').replace(\",\", '').replace(\"'\", '').strip()\n",
        "        # print(clear_line)\n",
        "        # print(clear_line.split(\":\"))\n",
        "        _split_into_list = clear_line.split(\":\") \n",
        "        # word, emotion = clear_line.split(':')\n",
        "        word, emotion = _split_into_list[0], _split_into_list[-1]\n",
        "\n",
        "        if word in final_words:\n",
        "            emotion_list.append(emotion)\n",
        "\n",
        "print(emotion_list)\n",
        "w = Counter(emotion_list)\n",
        "print(w)\n",
        "print(w.keys())\n",
        "\n",
        "# Plotting the emotions on the graph\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.bar(w.keys(), w.values(), color=['black', 'red', 'green', 'blue', 'cyan',\"yellow\"])\n",
        "fig.autofmt_xdate()\n",
        "plt.ylabel(\"sentiment level\")\n",
        "plt.xlabel(\"sentiment emotions\")\n",
        "plt.savefig('graph2.png')\n",
        "ax1.set_title('Akuffo Addos sentiment in 2019')\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ]
}